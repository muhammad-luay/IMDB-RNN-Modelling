{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "if not tf.__version__.startswith('2'):\n",
    "    raise ValueError('This code requires TensorFlow V2.x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data), info = tfds.load(\n",
    "    'imdb_reviews',\n",
    "    split=[tfds.Split.TRAIN, tfds.Split.TEST],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# Tokenize and pad the reviews\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "train_sentences, train_labels = zip(*[(sent.numpy().decode('utf8'), label.numpy()) for sent, label in train_data])\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "test_sentences, test_labels = zip(*[(sent.numpy().decode('utf8'), label.numpy()) for sent, label in test_data])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(10000, 64),\n",
    "    keras.layers.SimpleRNN(64),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 18s 22ms/step - loss: 0.6941 - accuracy: 0.5172 - val_loss: 0.6925 - val_accuracy: 0.5174\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6650 - accuracy: 0.5926 - val_loss: 0.7660 - val_accuracy: 0.5042\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6054 - accuracy: 0.6712 - val_loss: 0.7146 - val_accuracy: 0.5406\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5295 - accuracy: 0.7248 - val_loss: 0.7645 - val_accuracy: 0.5749\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.4356 - accuracy: 0.7876 - val_loss: 0.7763 - val_accuracy: 0.6078\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3917 - accuracy: 0.8140 - val_loss: 0.7221 - val_accuracy: 0.5491\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.4030 - accuracy: 0.8115 - val_loss: 0.9223 - val_accuracy: 0.5700\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3385 - accuracy: 0.8418 - val_loss: 1.0148 - val_accuracy: 0.5286\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3266 - accuracy: 0.8493 - val_loss: 1.1292 - val_accuracy: 0.5349\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.2954 - accuracy: 0.8648 - val_loss: 1.1917 - val_accuracy: 0.5480\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 12s 14ms/step - loss: 0.7146 - accuracy: 0.5183 - val_loss: 0.7044 - val_accuracy: 0.5380\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.6914 - accuracy: 0.5749 - val_loss: 0.6794 - val_accuracy: 0.6038\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.6105 - accuracy: 0.6842 - val_loss: 0.5641 - val_accuracy: 0.7507\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.4341 - accuracy: 0.8148 - val_loss: 0.5487 - val_accuracy: 0.7716\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.3399 - accuracy: 0.8662 - val_loss: 0.5917 - val_accuracy: 0.7576\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3198 - accuracy: 0.8720 - val_loss: 0.6870 - val_accuracy: 0.6710\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4039 - accuracy: 0.8154 - val_loss: 0.7807 - val_accuracy: 0.6171\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(10000, 32), # Reduced embedding dimension\n",
    "    keras.layers.Dropout(0.5), # Added dropout\n",
    "    keras.layers.SimpleRNN(32, kernel_regularizer=keras.regularizers.l2(0.001)), # L2 regularization\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Adding early stopping callback\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels), callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 98s 120ms/step - loss: 0.5122 - accuracy: 0.7501 - val_loss: 0.4354 - val_accuracy: 0.8051\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.3447 - accuracy: 0.8626 - val_loss: 0.4804 - val_accuracy: 0.8075\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 98s 125ms/step - loss: 0.2945 - accuracy: 0.8852 - val_loss: 0.4370 - val_accuracy: 0.8124\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 97s 123ms/step - loss: 0.2665 - accuracy: 0.8990 - val_loss: 0.4887 - val_accuracy: 0.8044\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, LSTM\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(10000, 32),\n",
    "    Bidirectional(LSTM(32, dropout=0.5, recurrent_dropout=0.5, kernel_regularizer=keras.regularizers.l2(0.001))),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels), callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 47s 52ms/step - loss: 0.5050 - accuracy: 0.7582 - val_loss: 0.4335 - val_accuracy: 0.8117\n",
      "Epoch 2/10\n",
      "  3/782 [..............................] - ETA: 36s - loss: 0.4024 - accuracy: 0.8333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadluay/opt/miniconda3/envs/tensyflow/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 41s 52ms/step - loss: 0.3505 - accuracy: 0.8554 - val_loss: 0.4137 - val_accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.3053 - accuracy: 0.8781 - val_loss: 0.3992 - val_accuracy: 0.8236\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 42s 53ms/step - loss: 0.2723 - accuracy: 0.8951 - val_loss: 0.4099 - val_accuracy: 0.8208\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 42s 53ms/step - loss: 0.2429 - accuracy: 0.9115 - val_loss: 0.5047 - val_accuracy: 0.7852\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 41s 53ms/step - loss: 0.2078 - accuracy: 0.9269 - val_loss: 0.4410 - val_accuracy: 0.8169\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(10000, 32),\n",
    "    Conv1D(32, 7, activation='relu'),\n",
    "    MaxPooling1D(5),\n",
    "    Bidirectional(LSTM(32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5, kernel_regularizer=keras.regularizers.l2(0.001))),\n",
    "    Bidirectional(LSTM(32, dropout=0.5, recurrent_dropout=0.5, kernel_regularizer=keras.regularizers.l2(0.001))),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels), callbacks=[early_stop, checkpoint])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensyflow",
   "language": "python",
   "name": "tensyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
